{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kywwuNna24Au"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WaG-8U8z4RDw",
    "outputId": "a637b213-b7b0-452c-c022-74191fbd9225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99VcWHMJ41ad",
    "outputId": "a89253f0-8740-4286-9965-c5a765d94cc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = torch.tensor(7)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqBFFvbs8qPG",
    "outputId": "1fd1451e-d733-41aa-d96b-962f5418a543"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8qYqXSI8xbo",
    "outputId": "484989d8-759d-46e4-f4eb-96346b66316d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIwwPf7R8zD3",
    "outputId": "a5a8f8fc-c5a1-47cb-cd73-9fd13982b619"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUhcmUGX89Cl",
    "outputId": "8459111e-45e6-4d40-98c4-6269c50ce9fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7pN4BwA9GYX",
    "outputId": "e86be68a-c3b7-4250-9dd5-886d409a4a4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "95UJsatH9K-T"
   },
   "outputs": [],
   "source": [
    "MATRIX = torch.tensor([[6, 7],\n",
    "                       [8, 9]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qL6CqFJi9muO",
    "outputId": "95313ee7-c61c-4092-c440-c23861893159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBmerZHx-jOP",
    "outputId": "f3c5cd2d-8d32-4ef7-aa1a-66099414e592"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VRBpC8c9t_t",
    "outputId": "334b238c-da62-4814-d63e-f764e4622f49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24VqXSre-dSi",
    "outputId": "1e3c697c-34fe-4373-cfac-585b95f28749"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2WjaUx2-emd",
    "outputId": "de771f3b-8449-4af1-91e8-bd28cfdd4135"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 4, 5],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 4, 5],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPxAYw-q_BLb",
    "outputId": "1bf010e0-9fce-4c92-c635-7e385dfe2d63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MUVWjBI_Fk8",
    "outputId": "f7dabf42-3899-4652-ad2e-288c17b936a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxgHUvnE_HlB",
    "outputId": "0b472461-24d1-4626-88f6-c80311083356"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 4, 5],\n",
       "        [2, 4, 5]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQ3-eQAhAnvP",
    "outputId": "ae7b0176-ad6e-45c1-8c06-cdbff3e193e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmdcqCrcAq2t",
    "outputId": "8c31cd88-c2f9-41ce-9ab8-b1b47f2372b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "eKLcik8hAvOp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4136, 0.8317, 0.8100, 0.2342],\n",
       "        [0.3056, 0.4711, 0.6434, 0.1069],\n",
       "        [0.4974, 0.9584, 0.9175, 0.2795]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,4) \n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0259, 0.9240, 0.8894, 0.8615, 0.3485, 0.7770, 0.7605, 0.0912,\n",
       "          0.8825, 0.9968],\n",
       "         [0.8439, 0.9368, 0.2466, 0.0624, 0.1661, 0.5086, 0.6222, 0.9654,\n",
       "          0.7391, 0.5583],\n",
       "         [0.1947, 0.3275, 0.3919, 0.8947, 0.1595, 0.8586, 0.5031, 0.0693,\n",
       "          0.9685, 0.8229],\n",
       "         [0.5211, 0.2393, 0.1965, 0.3153, 0.2382, 0.3689, 0.5072, 0.3150,\n",
       "          0.0256, 0.4389],\n",
       "         [0.5986, 0.8072, 0.3025, 0.9006, 0.0501, 0.9381, 0.4409, 0.9151,\n",
       "          0.1355, 0.0287],\n",
       "         [0.7805, 0.1438, 0.0277, 0.4889, 0.4880, 0.6090, 0.5192, 0.1205,\n",
       "          0.5509, 0.8858],\n",
       "         [0.6132, 0.9460, 0.1699, 0.7664, 0.0121, 0.5402, 0.5846, 0.6092,\n",
       "          0.7515, 0.1606],\n",
       "         [0.3445, 0.0496, 0.6624, 0.7824, 0.4967, 0.0704, 0.3259, 0.1400,\n",
       "          0.0770, 0.0718],\n",
       "         [0.7189, 0.5044, 0.0350, 0.3379, 0.9718, 0.7478, 0.2271, 0.7976,\n",
       "          0.6812, 0.6932],\n",
       "         [0.8238, 0.5082, 0.0666, 0.0839, 0.1611, 0.4587, 0.8873, 0.2440,\n",
       "          0.6895, 0.2516]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(1, 10,10) \n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5080, 0.4279, 0.8866],\n",
       "         [0.3827, 0.7236, 0.1101],\n",
       "         [0.5506, 0.0038, 0.5631],\n",
       "         ...,\n",
       "         [0.1989, 0.6847, 0.0447],\n",
       "         [0.1590, 0.9091, 0.4693],\n",
       "         [0.1722, 0.9684, 0.7078]],\n",
       "\n",
       "        [[0.1857, 0.1013, 0.4615],\n",
       "         [0.5032, 0.2991, 0.9636],\n",
       "         [0.7039, 0.3554, 0.3849],\n",
       "         ...,\n",
       "         [0.2514, 0.5260, 0.5160],\n",
       "         [0.2763, 0.9554, 0.0049],\n",
       "         [0.1272, 0.1795, 0.1911]],\n",
       "\n",
       "        [[0.5233, 0.0798, 0.6682],\n",
       "         [0.4120, 0.1972, 0.2557],\n",
       "         [0.9588, 0.5852, 0.6871],\n",
       "         ...,\n",
       "         [0.2479, 0.4228, 0.8191],\n",
       "         [0.8805, 0.7590, 0.4558],\n",
       "         [0.8466, 0.6995, 0.2262]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8756, 0.6762, 0.8820],\n",
       "         [0.0851, 0.7973, 0.5498],\n",
       "         [0.8329, 0.9816, 0.8320],\n",
       "         ...,\n",
       "         [0.9948, 0.9996, 0.6097],\n",
       "         [0.3239, 0.3046, 0.9549],\n",
       "         [0.7402, 0.6143, 0.8637]],\n",
       "\n",
       "        [[0.3818, 0.7167, 0.7522],\n",
       "         [0.8936, 0.8112, 0.5023],\n",
       "         [0.2900, 0.0202, 0.2799],\n",
       "         ...,\n",
       "         [0.2478, 0.6385, 0.8441],\n",
       "         [0.4604, 0.1686, 0.1732],\n",
       "         [0.5195, 0.8538, 0.4750]],\n",
       "\n",
       "        [[0.2212, 0.7159, 0.6490],\n",
       "         [0.7977, 0.0334, 0.7032],\n",
       "         [0.6563, 0.5562, 0.9761],\n",
       "         ...,\n",
       "         [0.8311, 0.6923, 0.3632],\n",
       "         [0.7642, 0.9237, 0.4528],\n",
       "         [0.8303, 0.3224, 0.6822]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor with similar shape of an image\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # height, width, color channels (R,G,B)\n",
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(3, 3)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onse = torch.ones(2, 3)\n",
    "onse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onse.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(1, 11)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=0, end=1000, step=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros = torch.zeros_like(one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor datatypes\n",
    "\n",
    "**note:** tensor data types is one of the 3 big errors you'll run into with pytorch & deep learnig:\n",
    "1. tensors not right data types\n",
    "2. tensors not right shape\n",
    "3. tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3.0, 6.0, 9.0]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3.0, 6.0, 9.0], dtype=None).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3.0, 6.0, 9.0],\n",
    "             dtype=None, # what data type is the tensor (float32 or float16)\n",
    "             device=None, # what device is your tenosr on \n",
    "             requires_grad=False # whether or not to track gradients with this tensors operations \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting infromation about tenosrs (tensor attributes)\n",
    "1. to get date type of a tensor, use `tensor.dtype`\n",
    "2. to get shape from a tensor, use `tensor.shape`\n",
    "3. to get device from a tensor, use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9522, 0.0091, 0.0723, 0.0204],\n",
       "        [0.5692, 0.5209, 0.2219, 0.9780],\n",
       "        [0.7116, 0.9252, 0.9608, 0.0926]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9522, 0.0091, 0.0723, 0.0204],\n",
      "        [0.5692, 0.5209, 0.2219, 0.9780],\n",
      "        [0.7116, 0.9252, 0.9608, 0.0926]])\n",
      "data type of tensor:torch.float32\n",
      "shape of tensor:torch.Size([3, 4])\n",
      "device tensor is on:cpu\n"
     ]
    }
   ],
   "source": [
    "print(some_tensor)\n",
    "print(f\"data type of tensor:{some_tensor.dtype}\")\n",
    "print(f\"shape of tensor:{some_tensor.shape}\")\n",
    "print(f\"device tensor is on:{some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.9522, 10.0091, 10.0723, 10.0204],\n",
       "        [10.5692, 10.5209, 10.2219, 10.9780],\n",
       "        [10.7116, 10.9252, 10.9608, 10.0926]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0663e-01, 8.2729e-05, 5.2296e-03, 4.1532e-04],\n",
       "        [3.2404e-01, 2.7132e-01, 4.9250e-02, 9.5651e-01],\n",
       "        [5.0637e-01, 8.5608e-01, 9.2309e-01, 8.5695e-03]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0952, 0.0009, 0.0072, 0.0020],\n",
       "        [0.0569, 0.0521, 0.0222, 0.0978],\n",
       "        [0.0712, 0.0925, 0.0961, 0.0093]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6666666666666665"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8//3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manupaltin tesnors\n",
    "\n",
    "tensors operatons include:\n",
    "* Adding\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multipliciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.9522, 5.0091, 5.0723, 5.0204],\n",
       "        [5.5692, 5.5209, 5.2219, 5.9780],\n",
       "        [5.7116, 5.9252, 5.9608, 5.0926]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = some_tensor + 5\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29.7609, 25.0455, 25.3616, 25.1019],\n",
       "        [27.8462, 27.6044, 26.1096, 29.8901],\n",
       "        [28.5580, 29.6262, 29.8039, 25.4629]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = some_tensor * 5\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24.7609, 20.0455, 20.3616, 20.1019],\n",
       "        [22.8462, 22.6044, 21.1096, 24.8901],\n",
       "        [23.5580, 24.6262, 24.8039, 20.4629]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = some_tensor - 5\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.9522, 4.0091, 4.0723, 4.0204],\n",
       "        [4.5692, 4.5209, 4.2219, 4.9780],\n",
       "        [4.7116, 4.9252, 4.9608, 4.0926]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = some_tensor / 5\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9043, 8.0182, 8.1446, 8.0408],\n",
       "        [9.1385, 9.0418, 8.4438, 9.9560],\n",
       "        [9.4232, 9.8505, 9.9215, 8.1851]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(some_tensor, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.9522, 5.0091, 5.0723, 5.0204],\n",
       "        [5.5692, 5.5209, 5.2219, 5.9780],\n",
       "        [5.7116, 5.9252, 5.9608, 5.0926]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(some_tensor, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplicaiton\n",
    "\n",
    "tow main ways of performing multiplicaton in neural networks and deep learning:\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "there are two main rules that performing matrix multiplication needs to satisfy:\n",
    "1. the **inner dimensions** must mach:\n",
    "* `(3, 2) @ (3, 2)` won't work\n",
    "* `(2, 3) @ (3, 2)` will work\n",
    "* `(3, 2) @ (2, 3)` will work\n",
    "2. the resulting matrix has the shape of the **outer dimensions**:\n",
    "* `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    "* `(3, 2) @ (2, 3)` -> `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24.5240, 16.0728, 16.5838, 16.1634],\n",
       "        [20.8780, 20.4384, 17.8246, 24.7806],\n",
       "        [22.1991, 24.2580, 24.6093, 16.7491]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element-wise multiplication\n",
    "some_tensor * some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_tensor1 = torch.rand(3,4)\n",
    "some_tensor2 = torch.rand(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5543, 0.3823, 0.2606],\n",
       "        [1.2326, 1.3165, 0.6791],\n",
       "        [1.2332, 1.4209, 0.9870]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "torch.matmul(some_tensor1, some_tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: user 1.03 ms, sys: 443 µs, total: 1.47 ms\n",
      "Wall time: 1.23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 433 µs, sys: 187 µs, total: 620 µs\n",
      "Wall time: 582 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one of the most common errors in deep learning: shape errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb Cell 65\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tensor_a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m                          [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                          [\u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m]])\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m tensor_b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m7\u001b[39m, \u001b[39m10\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                          [\u001b[39m8\u001b[39m, \u001b[39m11\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m                          [\u001b[39m9\u001b[39m, \u001b[39m12\u001b[39m]])\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m torch\u001b[39m.\u001b[39;49mmm(tensor_a, tensor_b) \u001b[39m# torch.mm is the as torch.matmul (it's an alias for writing less code)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "tensor_b = torch.tensor([[7, 10],\n",
    "                         [8, 11],\n",
    "                         [9, 12]])\n",
    "torch.mm(tensor_a, tensor_b) # torch.mm is the as torch.matmul (it's an alias for writing less code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a.shape, tensor_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.\n",
    "\n",
    "A **transpose** switches the axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8,  9],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_a, tensor_b.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum, etc(tensor aggregaion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x) # x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x) # x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb Cell 74\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m x\u001b[39m.\u001b[39;49mmean()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"torch.int64 is equals to torch.long\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46.)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(dtype=torch.float32) #torch.mean(x.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(460)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum() # torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmin() # returns index position of target tensor where the minimum value occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmax() # returns index position of target tensor where the maximum value occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) os side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimensions to a target tensor\n",
    "* Permute - Return a view of the input with dimennsions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor\n",
    "x = torch.arange(1.0, 10.)\n",
    "x , x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 7]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb Cell 86\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y151sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Add an extra dimension\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y151sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m x_reshaped \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m, \u001b[39m7\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y151sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m x_reshaped, x_reshaped\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 7]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 9]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb Cell 88\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y153sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m x_reshaped \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mreshape(\u001b[39m2\u001b[39;49m, \u001b[39m9\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y153sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m x_reshaped, x_reshaped\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 9]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "x_reshaped = x.reshape(2, 9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(9, 1)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.Size([10]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1.0, 11.)\n",
    "x , x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 3.,  4.],\n",
       "         [ 5.,  6.],\n",
       "         [ 7.,  8.],\n",
       "         [ 9., 10.]]),\n",
       " torch.Size([5, 2]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(5, 2)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([9]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10)\n",
    "x , x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the view\n",
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9]]), tensor([5, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing z changes x (because a view of a tensor shares the same memory as the original input )\n",
    "z[: ,0] = 5\n",
    "z ,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [5, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [5, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [5, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 5, 5, 5],\n",
       "        [2, 2, 2, 2],\n",
       "        [3, 3, 3, 3],\n",
       "        [4, 4, 4, 4],\n",
       "        [5, 5, 5, 5],\n",
       "        [6, 6, 6, 6],\n",
       "        [7, 7, 7, 7],\n",
       "        [8, 8, 8, 8],\n",
       "        [9, 9, 9, 9]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "x_stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x_reshaped.reshape(1, 10)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeeze() - removes all single dimensions from a target tensor\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "x_squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze() - adds a single dimension to a target tensor at a specific dim (dimension)\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "x_unsqueezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unsqueezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous shape: torch.Size([224, 224, 3])\n",
      "previous shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearranges the timensions of a target tensor in a specified order\n",
    "x_original = torch.rand(size=(224, 224, 3)) # [اheight, width, colour_channels]\n",
    "\n",
    "# permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f'previous shape: { x_original.shape}')\n",
    "print(f'previous shape: { x_permuted.shape}') # [colour_channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9452, 0.6567, 0.3052],\n",
       "         [0.4494, 0.5172, 0.4935],\n",
       "         [0.8873, 0.5144, 0.9885],\n",
       "         ...,\n",
       "         [0.9870, 0.7763, 0.7745],\n",
       "         [0.1898, 0.9142, 0.9512],\n",
       "         [0.5033, 0.4829, 0.7730]],\n",
       "\n",
       "        [[0.4708, 0.1138, 0.6871],\n",
       "         [0.7596, 0.4331, 0.0534],\n",
       "         [0.3834, 0.8546, 0.3686],\n",
       "         ...,\n",
       "         [0.6968, 0.2672, 0.7443],\n",
       "         [0.9589, 0.5831, 0.8937],\n",
       "         [0.8953, 0.4913, 0.6038]],\n",
       "\n",
       "        [[0.0758, 0.3348, 0.8879],\n",
       "         [0.0925, 0.6748, 0.7462],\n",
       "         [0.0941, 0.8616, 0.3273],\n",
       "         ...,\n",
       "         [0.7798, 0.3008, 0.7102],\n",
       "         [0.2439, 0.9247, 0.1040],\n",
       "         [0.6504, 0.8874, 0.7125]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4605, 0.2659, 0.9222],\n",
       "         [0.1997, 0.5817, 0.3401],\n",
       "         [0.8814, 0.9362, 0.1417],\n",
       "         ...,\n",
       "         [0.0457, 0.5593, 0.8653],\n",
       "         [0.8833, 0.5604, 0.9272],\n",
       "         [0.8844, 0.0074, 0.8839]],\n",
       "\n",
       "        [[0.6636, 0.1240, 0.4604],\n",
       "         [0.6574, 0.5261, 0.5386],\n",
       "         [0.6379, 0.4140, 0.7240],\n",
       "         ...,\n",
       "         [0.4783, 0.4608, 0.8009],\n",
       "         [0.6895, 0.9441, 0.7655],\n",
       "         [0.3948, 0.0153, 0.9295]],\n",
       "\n",
       "        [[0.1981, 0.2215, 0.1291],\n",
       "         [0.9326, 0.1565, 0.2630],\n",
       "         [0.7103, 0.9360, 0.9397],\n",
       "         ...,\n",
       "         [0.1132, 0.6709, 0.5605],\n",
       "         [0.4727, 0.7708, 0.9881],\n",
       "         [0.2476, 0.0162, 0.1434]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9452, 0.6567, 0.3052])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9452)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(728218.), tensor(728218.))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0] = 728218\n",
    "x_original[0, 0, 0], x_permuted[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (selection data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb Cell 114\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m x[\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "x[1][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can use \":\" to select \"all\" of a target dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th and 1st dimensions but only index 1 and 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index of 0 of 0th and 1st dimension and all values of the 2nd dimension\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index on x to return 9\n",
    "x[0, 2, 2] # is equals to x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index on x to return 3, 6, 9\n",
    "x[0, :, 2]# is not equals to x[0][:][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy\n",
    "\n",
    "NumPy is a popular scientific python numerical computing library and because of this, PyTorch has functionality to interact with it.\n",
    "\n",
    "* Data in NumPy, want to PyTorch tensor -> `torch.form_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) #warning: when converting from numpy to pytorch\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype # this isn't pytorch default type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1.0, 8.0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype # tensor with default type from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the value of array< what this will do to `tensor`?\n",
    "array += 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to numpy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([2., 2., 2., 2., 2., 2., 2.], dtype=float32))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the tensor, what happens to `numpy_tensor`?\n",
    "tensor += 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducbility (trying to take random out of random)\n",
    "\n",
    "In short how a neural network learns:\n",
    "\n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again -> ...`\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**.\n",
    "\n",
    "Essentially what the random seed does is \"flavour\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6756, 0.4295, 0.9294, 0.0935],\n",
      "        [0.7411, 0.7103, 0.2935, 0.1209],\n",
      "        [0.8809, 0.2954, 0.4290, 0.6650]])\n",
      "tensor([[0.4618, 0.7801, 0.9239, 0.9650],\n",
      "        [0.8612, 0.5562, 0.0793, 0.2775],\n",
      "        [0.6404, 0.3071, 0.5581, 0.1542]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Create two random tensors\n",
    "random_tensor_a = torch.rand(3, 4)\n",
    "random_tensor_b = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_a)\n",
    "print(random_tensor_b)\n",
    "print(random_tensor_a == random_tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors\n",
    "\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 42 # whatever you want\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_a = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_b = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_a)\n",
    "print(random_tensor_b)\n",
    "print(random_tensor_a == random_tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on the GPUs (and making faster computations)\n",
    "\n",
    "GPUs = faster computation on numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU \n",
    "\n",
    "1. Easiest - Use Google Colab for a free GPU (options to upgrade as well)\n",
    "2. Use your own GPU - takes a little bit of setup and requires teh investment of purchasing a GPU, there's a lots of options...\n",
    "3. Use cloud computing - GCP, AWS, Azure, these services allows you to rent computers on the cloud and access them \n",
    "\n",
    "for 2, 3 PyTorch + GPU drivers (CUDA) takes a little bit of setting up, to do this, refer to PyTorch setup documenttion:https://pytorch.org/get-started/locally/    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check for GPU access with PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access with PyTorch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For PyTorch since it's capable of running compute on the GPU OR CPU, it's best practice to setup device agnostic code: https://pytorch.org/docs/stable/notes/cuda.html#best-practices\n",
    "\n",
    "E.g. run on GPU if available, else default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count() # the number of GPUs we have access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. putting tensors (and models) on the GPU \n",
    "\n",
    "the reason we want our tensors/models on the GPU is because using a GPU results in faster computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on the GPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3], device=\"cpu\")\n",
    "\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb Cell 146\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y310sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# If tensors is on GPU, can't transform it to NumPy\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/saleh/pyTorch/1_pytorch_fundamentals.ipynb#Y310sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m tensor_on_gpu\u001b[39m.\u001b[39;49mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensors is on GPU, can't transform it to NumPy\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fix the GPU tensor with NumPy issue, we can first set it to the CPU \n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMXaqnBqDNj83H34SD2O8m+",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
